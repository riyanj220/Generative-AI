{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3Dv_-8fW1sg"
   },
   "source": [
    "# **Setting Up the environment keys**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "import os\n",
    "\n",
    "HF_TOKEN = userdata.get(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "WEAVIATE_URL = userdata.get(\"WEAVIATE_URL\")\n",
    "WEAVIATE_API_KEY = userdata.get(\"WEAVIATE_API_KEY\")\n",
    "GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
    "\n",
    "# make HF token visible to libraries that expect env var\n",
    "if HF_TOKEN:\n",
    "    os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HF_TOKEN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHBFd_UsW7We"
   },
   "source": [
    "# **Installing and importing required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install \"weaviate-client<4\" \\\n",
    "                \"langchain>=0.2\" \"langchain-community>=0.2\" \"langchain-text-splitters>=0.2\" \\\n",
    "                sentence-transformers \\\n",
    "                unstructured \"unstructured[pdf]\" pypdf \\\n",
    "                langchain-google-genai \\\n",
    "                langchain-huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain bits\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Weaviate as WeaviateStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Data loading (you already shared)\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import TextLoader  # if you also use .txt later\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "# LLM (Gemini) – optional if you want HF LLM instead\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Weaviate client v3\n",
    "import weaviate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2_-VskaXI5n"
   },
   "source": [
    "# **Initializing Weaviate client**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = \"DocChunk\"    # Weaviate \"class\" name\n",
    "TEXT_KEY   = \"text\"        # property that will hold the raw chunk text\n",
    "\n",
    "client = weaviate.Client(\n",
    "    url=\"https://\"+WEAVIATE_URL,\n",
    "    auth_client_secret=weaviate.AuthApiKey(WEAVIATE_API_KEY),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quXEoGE1XOxa"
   },
   "source": [
    "# **Creating a class in our cluster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Weaviate class: DocChunk\n"
     ]
    }
   ],
   "source": [
    "# Create class if it doesn't exist\n",
    "existing = [c[\"class\"] for c in client.schema.get().get(\"classes\", [])]\n",
    "if INDEX_NAME not in existing:\n",
    "    class_obj = {\n",
    "        \"class\": INDEX_NAME,\n",
    "        \"description\": \"RAG document chunks\",\n",
    "        \"vectorizer\": \"none\",               # because we bring our own vectors\n",
    "        \"vectorIndexType\": \"hnsw\",\n",
    "        \"vectorIndexConfig\": {\"distance\": \"cosine\"},\n",
    "        \"properties\": [\n",
    "            {\"name\": TEXT_KEY,   \"dataType\": [\"text\"]},\n",
    "            {\"name\": \"source\",   \"dataType\": [\"text\"]},\n",
    "            {\"name\": \"chunk_id\", \"dataType\": [\"int\"]},\n",
    "        ],\n",
    "    }\n",
    "    client.schema.create_class(class_obj)\n",
    "    print(f\"Created Weaviate class: {INDEX_NAME}\")\n",
    "else:\n",
    "    print(f\"Weaviate class already exists: {INDEX_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YyHw6x1tXTzJ"
   },
   "source": [
    "# **If you want to delete the class ( If any thing goes wrong )**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.schema.delete_class(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSOEJYEpXbHb"
   },
   "source": [
    "# **Using hugging face model for embeddings**\n",
    "because weaviate has limit of 1536 dimension and gemini has 3072 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_MODEL = \"Alibaba-NLP/gte-large-en-v1.5\"\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=EMBED_MODEL,\n",
    "    model_kwargs={\"trust_remote_code\": True},  # needed for some sentence-transformers wrappers\n",
    "    encode_kwargs={\"batch_size\": 32}  # process 32 chunks at a time\n",
    ")\n",
    "\n",
    "# sanity check: print dimension (must be <= 1536 for Weaviate)\n",
    "dim = len(embedding.embed_query(\"dimension test\"))\n",
    "print(\"Embedding dimension:\", dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uaZRsy_0Xp_Z"
   },
   "source": [
    "# **Loading and preparing our data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1hPQlXrX8FbaYaLypxTmeVOFNitbBMlEE\n",
      "To: /content/pdfs/yolov7paper.pdf\n",
      "100% 2.27M/2.27M [00:00<00:00, 18.7MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1vILwiv6nS2wI3chxNabMgry3qnV67TxM\n",
      "To: /content/pdfs/rachelgreecv.pdf\n",
      "100% 271k/271k [00:00<00:00, 5.57MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown 1hPQlXrX8FbaYaLypxTmeVOFNitbBMlEE -O pdfs/yolov7paper.pdf\n",
    "!gdown 1vILwiv6nS2wI3chxNabMgry3qnV67TxM -O pdfs/rachelgreecv.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFDirectoryLoader(\"pdfs\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "text_chunks = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "keCthEWUXuIW"
   },
   "source": [
    "# **Weaviate requires that all property names in the schema (and the metadata you upsert) follow GraphQL naming rules:**\n",
    "\n",
    "1. Must start with a letter (A–Z or a–z) or underscore _.\n",
    "\n",
    "2. Followed by letters, numbers, or underscores.\n",
    "\n",
    "3. Length ≤ 231 chars.\n",
    "\n",
    "4. No dots (.), dashes (-), or special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in text_chunks:\n",
    "    clean_metadata = {}\n",
    "    for k, v in doc.metadata.items():\n",
    "        # Replace '.' with '_' and enforce GraphQL-safe naming\n",
    "        safe_key = k.replace(\".\", \"_\")\n",
    "        clean_metadata[safe_key] = v\n",
    "    doc.metadata = clean_metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBcWkx15YAHg"
   },
   "source": [
    "# **Now storing our cleaned data in the form of embeddings in weaviate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chunks embedded and stored in Weaviate.\n"
     ]
    }
   ],
   "source": [
    "# Vectorstore wrapper around Weaviate\n",
    "vectorstore = WeaviateStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    embedding=embedding,\n",
    "    client=client,\n",
    "    index_name=INDEX_NAME,\n",
    "    text_key=TEXT_KEY,\n",
    ")\n",
    "\n",
    "print(\"✅ Chunks embedded and stored in Weaviate.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYi8B1LbYJ7e"
   },
   "source": [
    "# **Building RAG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nk => get top-k most similar chunks\\nProblem: they might all be very similar to each other → you lose diversity.\\n\\n\\nsearch_type = \"mmmr\" => MMR tries to balance:\\nRelevance (is the chunk close to the query?)\\nDiversity (are the chunks different from each other?)\\n\\nThis avoids redundancy (e.g., getting 3 nearly identical chunks from one page).\\n\\n\\nfetch_k => how many initial candidates to pull from the vector store before applying the MMR selection.\\n\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 3, \"fetch_k\": 24})\n",
    "'''\n",
    "k => get top-k most similar chunks\n",
    "Problem: they might all be very similar to each other → you lose diversity.\n",
    "\n",
    "\n",
    "search_type = \"mmmr\" => MMR tries to balance:\n",
    "Relevance (is the chunk close to the query?)\n",
    "Diversity (are the chunks different from each other?)\n",
    "\n",
    "This avoids redundancy (e.g., getting 3 nearly identical chunks from one page).\n",
    "\n",
    "\n",
    "fetch_k => how many initial candidates to pull from the vector store before applying the MMR selection.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",           # or \"gemini-1.5-pro\" if you want stronger reasoning\n",
    "    google_api_key=GEMINI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      " The provided text discusses several papers focusing on improving Convolutional Neural Networks (CNNs).  Key themes include:\n",
      "\n",
      "* **Efficient scaling of CNNs:** One paper explores a compound scaling strategy that efficiently improves accuracy by scaling both width and depth of the network, outperforming strategies that scale only width or depth.\n",
      "\n",
      "* **Reparamaterization of optimizers and architectures:** Another paper investigates re-parameterizing optimizers instead of modifying network architectures for improved performance.\n",
      "\n",
      "* **Novel architectural blocks:**  Several papers introduce new building blocks for CNNs, such as asymmetric convolution blocks and diverse branch blocks, aimed at enhancing performance.  One paper specifically focuses on replacing conventional convolution blocks with RepConv blocks within a specific architecture (ELAN).\n",
      "\n",
      "The papers present ablation studies and experimental results demonstrating the effectiveness of their proposed methods.  Specific performance metrics (AP, FLOPs, # parameters) are reported, but the exact values and comparisons are too numerous to summarize concisely here.\n",
      "\n",
      "Sources:\n",
      "- pdfs/yolov7paper.pdf …\n",
      "- pdfs/yolov7paper.pdf …\n",
      "- pdfs/yolov7paper.pdf …\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me a concise summary of the key ideas in these PDFs.\"\n",
    "query_2 = \"Tell me about Riyan\" # for testing\n",
    "resp = qa.invoke({\"query\": query})\n",
    "\n",
    "print(\"Answer:\\n\", resp[\"result\"])\n",
    "print(\"\\nSources:\")\n",
    "for d in resp[\"source_documents\"]:\n",
    "    print(\"-\", d.metadata.get(\"source\"), \"…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
