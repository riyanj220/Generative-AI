{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------#\n",
    "#                NLP TASKS                              #\n",
    "#-------------------------------------------------------#\n",
    "\n",
    "'''\n",
    "1. Text Classification: Assigning a category to a piece of text\n",
    "Sentiment analysis\n",
    "Spam detection\n",
    "'''\n",
    "\n",
    "classifier = pipeline(\"text-classification\")\n",
    "\n",
    "'''\n",
    "2. Token classification: Assigning a label to each token in a sequence\n",
    "Named entity recognition (NER)\n",
    "Part-of-speech tagging\n",
    "'''\n",
    "\n",
    "token_classifier = pipeline(\"token-classification\")\n",
    "\n",
    "'''\n",
    "3. Question answering: Answering a question based on a context\n",
    "'''\n",
    "\n",
    "question_answerer = pipeline(\"question-answering\")\n",
    "\n",
    "\n",
    "'''\n",
    "4. Text generation: Generating new text based on a given prompt\n",
    "Language modeling\n",
    "Story generation\n",
    "'''\n",
    "\n",
    "generator = pipeline(\"text-generation\")\n",
    "\n",
    "\n",
    "'''\n",
    "5. Summarization: Generating a concise summary of a longer text\n",
    "'''\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "\n",
    "'''\n",
    "5. Translation: Converting text from one language to another\n",
    "'''\n",
    "\n",
    "translator = pipeline(\"translation\",model=\"Helsinki-NLP/opus-mt-en-fr\")\n",
    "\n",
    "\n",
    "'''\n",
    "6. Text2Text generation: Generating new text based on a given prompt, General purpose text summarization including\n",
    "translation and summarization\n",
    "'''\n",
    "\n",
    "text2text_generator = pipeline(\"text2text-generation\")\n",
    "\n",
    "\n",
    "'''\n",
    "7. Fill-mask: Filling in the blanks in a given text, predicting missing words in a sentence\n",
    "'''\n",
    "\n",
    "unmasker = pipeline(\"fill-mask\")\n",
    "\n",
    "\n",
    "'''\n",
    "8. Feature extraction: Extracting hidden states or features from text.\n",
    "'''\n",
    "\n",
    "feature_extractor = pipeline(\"feature-extraction\")\n",
    "\n",
    "\n",
    "'''\n",
    "9. Sentence similarity: Measuring the similarity between two sentences\n",
    "'''\n",
    "\n",
    "similarity = pipeline(\"sentence-similarity\")\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------------------------------------#\n",
    "#                COMPUTER VISION TASKS                  #\n",
    "#-------------------------------------------------------#\n",
    "\n",
    "'''\n",
    "1. Image classification: Classifying the main content of an image\n",
    "'''\n",
    "\n",
    "image_classifier = pipeline(\"image-classification\")\n",
    "\n",
    "\n",
    "'''\n",
    "2. Object detection: Identifying and localizing objects in an image\n",
    "'''\n",
    "\n",
    "object_detector = pipeline(\"object-detection\")\n",
    "\n",
    "\n",
    "'''\n",
    "3. Image segmentation: Assigning a label to each pixel in an image\n",
    "'''\n",
    "\n",
    "image_segmenter = pipeline(\"image-segmentation\")\n",
    "\n",
    "\n",
    "'''\n",
    "4. Image generation: Generating new images based on a given prompt (Using DALL-E or similar models)\n",
    "'''\n",
    "\n",
    "image_generator = pipeline(\"image-generation\")\n",
    "\n",
    "\n",
    "#-------------------------------------------------------#\n",
    "#                SPEECH PROCESSING TASKS                #\n",
    "#-------------------------------------------------------#\n",
    "\n",
    "'''\n",
    "1. Automatic speech recognition(ASR): Converting spoken language into text\n",
    "'''\n",
    "speech_recognizer = pipeline(\"automatic-speech-recognition\")\n",
    "\n",
    "\n",
    "'''\n",
    "2. Text-to-speech(TTS): Converting text into spoken language\n",
    "'''\n",
    "\n",
    "text_to_speech = pipeline(\"text-to-speech\")\n",
    "\n",
    "'''\n",
    "3. Speech translation: Converting speech from one language to another\n",
    "'''\n",
    "\n",
    "speech_translator = pipeline(\"speech-translation\")\n",
    "\n",
    "\n",
    "'''\n",
    "4. Audio classification: Classifying the main content of an audio file\n",
    "'''\n",
    "\n",
    "audio_classifier = pipeline(\"audio-classification\")\n",
    "\n",
    "\n",
    "'''\n",
    "5. Audio transcription: Converting spoken language into text\n",
    "'''\n",
    "audio_recognizer = pipeline(\"audio-transcription\")\n",
    "\n",
    "\n",
    "#-------------------------------------------------------#\n",
    "#                MULTIMODAL TASKS                       #\n",
    "#-------------------------------------------------------#\n",
    "\n",
    "'''\n",
    "1. Image captioning: Generating a descriptive caption for an image\n",
    "'''\n",
    "\n",
    "image_captioner = pipeline(\"image-to-text\")\n",
    "\n",
    "\n",
    "'''\n",
    "2. Visual question answering (VQA) : Answering a question about an image\n",
    "'''\n",
    "\n",
    "visual_question_answerer = pipeline(\"visual-question-answering\")\n",
    "\n",
    "\n",
    "#-------------------------------------------------------#\n",
    "#                OTHER TASKS                            #\n",
    "#-------------------------------------------------------#\n",
    "\n",
    "'''\n",
    "1. Table question answering: Answering a question about a table\n",
    "'''\n",
    "\n",
    "table_question_answerer = pipeline(\"table-question-answering\")\n",
    "\n",
    "\n",
    "'''\n",
    "2. Document question answering: Extracting answers from documents like PDF\n",
    "'''\n",
    "\n",
    "document_question_answerer = pipeline(\"document-question-answering\")\n",
    "\n",
    "\n",
    "'''\n",
    "3. Time series forecasting: Predicting future values of a time series\n",
    "'''\n",
    "\n",
    "time_series_forecaster = pipeline(\"time-series-forecasting\")\n",
    "\n",
    "\n",
    "'''\n",
    "4. Anomaly detection: Identifying unusual patterns in a dataset\n",
    "'''\n",
    "\n",
    "anomaly_detector = pipeline(\"anomaly-detection\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTRm0HKGo7K9"
   },
   "source": [
    "# **NLP TASKS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEV0_Dkno--v"
   },
   "source": [
    "## **Sentiment analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "result = classifier(\"I hate you\")[0]\n",
    "print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(task = 'sentiment-analysis')('I was very confused with the new batman movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(task = 'sentiment-analysis', model = 'facebook/bart-large-mnli')\\\n",
    "                            ('I was very confused with the new batman movie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4Dy8U8FY6Rw"
   },
   "source": [
    "## **Batch Sentiment Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline('sentiment-analysis')\n",
    "\n",
    "task_list = ['I really like autoencoders, best model for anomaly detection', \\\n",
    "             'I am not sure if we can actually evaluate LLMS.', \\\n",
    "             'PassiveAggressive is the name of linear regression model that so many people dont know.' , \\\n",
    "             'I hate long meetings.']\n",
    "\n",
    "classifier(task_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline('sentiment-analysis', model='SamLowe/roberta-base-go_emotions')\n",
    "\n",
    "task_list = ['I really like autoencoders, best model for anomaly detection', \\\n",
    "             'I am not sure if we can actually evaluate LLMS.', \\\n",
    "             'PassiveAggressive is the name of linear regression model that so many people dont know.' , \\\n",
    "             'I hate long meetings.']\n",
    "\n",
    "classifier(task_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuSGuq4Qaeuo"
   },
   "source": [
    "## **Text Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "text_generator = pipeline('text-generation' , model = 'distilbert/distilgpt2')\n",
    "generated_text = text_generator('Today is a rainy day in London',\n",
    "                                truncation = True,\n",
    "                                num_return_sequences=2)\n",
    "print('Generated text:\\n', generated_text[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PC53yTA4bdXz"
   },
   "source": [
    "## **Question Answering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa_model = pipeline('question-answering')\n",
    "question = 'What is my job?'\n",
    "context = 'I am developing AI models with Python'\n",
    "answer = qa_model(question=question , context = context)\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8iHZHuHyeRW5"
   },
   "source": [
    "## **Tokenization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DistilBertTokenizer, DistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model_name1 = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "my_tokenizer1 = DistilBertTokenizer.from_pretrained(model_name1)\n",
    "my_model1 = DistilBertForSequenceClassification.from_pretrained(model_name1)\n",
    "\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "res = classifier('I was not so happy with the Batman movie')\n",
    "res\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "model_name2 = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
    "my_tokenizer2 = AutoTokenizer.from_pretrained(model_name2)\n",
    "my_model2 = AutoModelForSequenceClassification.from_pretrained(model_name2)\n",
    "\n",
    "classifier = pipeline('sentiment-analysis' ,model = my_model2 , tokenizer = my_tokenizer2)\n",
    "res = classifier('I was not so happy with the Batman movie')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load a pre trained tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "# Example text\n",
    "text = \"I was not so happy with the batman movie\"\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = tokenizer.tokenize(text)\n",
    "\n",
    "# Print the tokens\n",
    "print(\"Tokens: \", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tokens into input ID's\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "# Print the input IDs\n",
    "print(\"Input IDs: \", input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the text (tokenization+converting into Input ID's)\n",
    "encoded_input = tokenizer(text)\n",
    "\n",
    "# Print the encoded input\n",
    "print(\"Encoded Input: \", encoded_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the text\n",
    "decoded_output = tokenizer.decode(encoded_input['input_ids'])\n",
    "\n",
    "# Print the decoded output\n",
    "print(\"Decoded Output: \", decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWCYETS1XY3P"
   },
   "source": [
    "# **Fine Tuning IMDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets # if you want to use hugging face datasets so you have to download this library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1Ax7JZlYP7b"
   },
   "source": [
    "## **Loading and Preparing the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEVGaX_TYtGu"
   },
   "source": [
    "## **Pre Processing the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=64)\n",
    "    # padding: Matlb pehly maximum length ka sentence dhond kar uske baad baki short sentences ko oske brabar karna hy 0 laga kar\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wl8qAxQtaI3A"
   },
   "source": [
    "## **Setting up the training arguements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir='./results',\n",
    "         eval_strategy='epoch',\n",
    "         learning_rate = 2e-5,\n",
    "         per_device_train_batch_size=16,\n",
    "         per_device_eval_batch_size=16,\n",
    "         num_train_epochs=0.3,\n",
    "         weight_decay=0.01)\n",
    "\n",
    "training_args\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVY40GnEdoGn"
   },
   "source": [
    "## **Initialize the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the pre trained model and defining the training process\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, Trainer\n",
    "\n",
    "# load the pre trained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-cased', num_labels=2) # beacause we are having 2 labels +ve,-ve\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer (\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_datasets['train'],\n",
    "    eval_dataset = tokenized_datasets['test']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyt8gvTbeSf0"
   },
   "source": [
    "## **Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_P1GeALCrz9r"
   },
   "source": [
    "## **Evaluate The model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yb2sRAQ_sh-3"
   },
   "source": [
    "## **Save the fine tuned model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('./fine-tuned-model')\n",
    "tokenizer.save_pretrained('./fine-tuned-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model with a movie review\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "model_path = './fine-tuned-model'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "classifier = pipeline('sentiment-analysis', model = model, tokenizer = tokenizer)\n",
    "\n",
    "review = \"The movie was absolutely fantastic, I loved the story and acting!\"\n",
    "result = classifier(review)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FN8ITP1JeV_E"
   },
   "source": [
    "# **Arxiv Project**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv # Research paper related Library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to fetch AI related papers\n",
    "query = 'ai or Artificial Intelligence or machine learning'\n",
    "search = arxiv.Search(query = query , max_results = 10 , sort_by=arxiv.SortCriterion.SubmittedDate)\n",
    "\n",
    "# Fetch papers\n",
    "papers = []\n",
    "for result in search.results():\n",
    "    papers.append(\n",
    "        {\n",
    "            'published':result.published,\n",
    "            'title': result.title,\n",
    "            'abstract': result.summary,\n",
    "            'category': result.categories\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Convert into dataframe\n",
    "df = pd.DataFrame(papers)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example abstract from API\n",
    "abstract = df['abstract'][0]\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model='facebook/bart-large-cnn')\n",
    "\n",
    "# Summarization\n",
    "summarization_result = summarizer(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Genie Envisioner is a unified world foundation platform for robotic manipulation. It integrates policy learning, evaluation, and simulation within a single video-generative framework. GE-Base is a large-scale, instruction-conditioned video diffusion model that captures dynamics of real-world robotic interactions in structured latent space.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarization_result[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
